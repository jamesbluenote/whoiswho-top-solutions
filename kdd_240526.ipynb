{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYdn1woOS1n",
        "outputId": "e4289dab-1b4f-459f-d04e-2fe7f13f3059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ./gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. GCN"
      ],
      "metadata": {
        "id": "7eGLSDIwp9ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "2dYK0uKWyL2u",
        "outputId": "e814e739-3054-4057-e016-892191622b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "fauVVUI02pzL",
        "outputId": "b82e2afe-2172-43b3-f88c-552b6211f924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.2.0 (from -r requirements.txt (line 2))\n",
            "  Downloading scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_geometric==2.5.2 (from -r requirements.txt (line 3))\n",
            "  Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.66.1 (from -r requirements.txt (line 4))\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.39.1 (from -r requirements.txt (line 5))\n",
            "  Downloading transformers-4.39.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Unidecode==1.3.8 (from -r requirements.txt (line 6))\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 3)) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 5)) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 5)) (0.23.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 5)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 5)) (2023.12.25)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.1->-r requirements.txt (line 5))\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 5)) (0.4.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.1->-r requirements.txt (line 5)) (4.11.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 3)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 3)) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.5.2->-r requirements.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.5.2->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.5.2->-r requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.5.2->-r requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.5.2->-r requirements.txt (line 3)) (2024.2.2)\n",
            "Installing collected packages: Unidecode, tqdm, numpy, tokenizers, scikit_learn, transformers, torch_geometric\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.0\n",
            "    Uninstalling transformers-4.41.0:\n",
            "      Successfully uninstalled transformers-4.41.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.6.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.2.0 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Unidecode-1.3.8 numpy-1.24.4 scikit_learn-1.2.0 tokenizers-0.15.2 torch_geometric-2.5.2 tqdm-4.66.1 transformers-4.39.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "36a30a9177f246bc9c9915362ef197fe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After Restarting Session"
      ],
      "metadata": {
        "id": "yc88q2JuRajE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "metadata": {
        "id": "kYHeDk-URZ6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "I6rBcfSURhRH",
        "outputId": "d71b2674-73dc-43b5-f39d-16e4e44a98c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "WqxdkDHLzkwW",
        "outputId": "b54a4d22-a137-4d14-ceba-507732332949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python encoding.py --path ../dataset/pid_to_info_all.json --save_path ../dataset/roberta_embeddings.pkl"
      ],
      "metadata": {
        "id": "Dv6o84KGznT8",
        "outputId": "c6dc58ce-fcbd-43ff-dd56-a5875567767a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "64it [09:02,  8.48s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python build_graph.py --author_dir ../dataset/train_author.json  --save_dir ../dataset/train.pkl"
      ],
      "metadata": {
        "id": "PbKv1ocDzyiU",
        "outputId": "e2051930-f860-4cd4-c10a-5e990709935f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "done clean pubs\n",
            "done loading embeddings\n",
            "Process ForkPoolWorker-12:\n",
            "Process ForkPoolWorker-19:\n",
            "Process ForkPoolWorker-11:\n",
            "Process ForkPoolWorker-13:\n",
            "Process ForkPoolWorker-15:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 215, in build_dataset\n",
            "Process ForkPoolWorker-17:\n",
            "Process ForkPoolWorker-16:\n",
            "Process ForkPoolWorker-18:\n",
            "Process ForkPoolWorker-14:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 98, in co_occurance\n",
            "    if(simple_name_match(per_n1, per_n2)):\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 40, in simple_name_match\n",
            "    n1_set = set(n1.split())\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 90, in co_occurance\n",
            "    if simple_name_match(core_name,name):\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 81, in co_occurance\n",
            "    ori_n1_authors = [clean_name(paper1[\"authors\"][ins_index][\"name\"]).strip() for ins_index in range(min(len(paper1[\"authors\"]), 50))]\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 81, in <listcomp>\n",
            "    ori_n1_authors = [clean_name(paper1[\"authors\"][ins_index][\"name\"]).strip() for ins_index in range(min(len(paper1[\"authors\"]), 50))]\n",
            "KeyboardInterrupt\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 32, in clean_name\n",
            "    if a.isalpha():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 77, in co_occurance\n",
            "    core_name = clean_name(core_name)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 35, in clean_name\n",
            "    new_name = new_name.strip()\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 90, in co_occurance\n",
            "    if simple_name_match(core_name,name):\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 46, in simple_name_match\n",
            "    if(len(com_set) == len(n1_set)):\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 98, in co_occurance\n",
            "    if(simple_name_match(per_n1, per_n2)):\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 40, in simple_name_match\n",
            "    n1_set = set(n1.split())\n",
            "KeyboardInterrupt\n",
            "    results = pool.map(getdata,keys_list)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 367, in map\n",
            "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 768, in get\n",
            "    self.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 765, in wait\n",
            "    self._event.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 301, in <module>\n",
            "Process ForkPoolWorker-20:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 120, in co_occurance\n",
            "    covenue_weight = jaccard_similarity(n1_venue,n2_venue)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 109, in jaccard_similarity\n",
            "    intersection = len(set(list1) & set(list2))\n",
            "KeyboardInterrupt\n",
            "    build_dataset(args.save_dir)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 215, in build_dataset\n",
            "    results = pool.map(getdata,keys_list)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 98, in co_occurance\n",
            "    if(simple_name_match(per_n1, per_n2)):\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 98, in co_occurance\n",
            "    if(simple_name_match(per_n1, per_n2)):\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 41, in simple_name_match\n",
            "    n2_set = set(n2.split())\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
            "    return list(map(*args))\n",
            "KeyboardInterrupt\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 145, in getdata\n",
            "    _, w_coauthor, w_coorg, w_covenue = co_occurance(author_names[orcid]['name'], paper1_inf, paper2_inf)\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 98, in co_occurance\n",
            "    if(simple_name_match(per_n1, per_n2)):\n",
            "  File \"/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCN/build_graph.py\", line 40, in simple_name_match\n",
            "    n1_set = set(n1.split())\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python build_graph.py --author_dir ../dataset/ind_valid_author.json  --save_dir ../dataset/valid.pkl"
      ],
      "metadata": {
        "id": "XGdpTNHAz4RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py  --train_dir ../dataset/train.pkl  --test_dir ../dataset/valid.pkl"
      ],
      "metadata": {
        "id": "xdJW8CP3z4g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. GCCAD"
      ],
      "metadata": {
        "id": "DhtzCE1tp4vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCCAD')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "9ZKEm4BnEXju",
        "outputId": "8d2fc440-77cd-4835-e858-d8fcdbb9fa16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCCAD'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJGBGI5strzA",
        "outputId": "cf92ea3c-4162-4946-9340-a9c2dc2a5b31"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_cluster-1.6.3%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.25.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt23cu121\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-jinlmw0w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-jinlmw0w\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit ca3b0f461d69ec9899fc9100887d3454b8d1f4cf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (3.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (1.25.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (4.66.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.6.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.6.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.6.0) (3.5.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.6.0-py3-none-any.whl size=1113505 sha256=e306118556aebd1997cb44937425c36f41bf6766ee894b9d741d70bb133f14f9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yjer_e9n/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "wy6y3mF0qAth",
        "outputId": "93030065-551e-47de-fee6-01ee9261ddde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4 (from -r requirements.txt (line 1))\n",
            "  Using cached numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting pyro_ppl==1.9.0 (from -r requirements.txt (line 2))\n",
            "  Using cached pyro_ppl-1.9.0-py3-none-any.whl (745 kB)\n",
            "Collecting scikit_learn==1.2.0 (from -r requirements.txt (line 3))\n",
            "  Using cached scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "Collecting scipy==1.12.0 (from -r requirements.txt (line 4))\n",
            "  Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "Collecting torch_geometric==2.5.2 (from -r requirements.txt (line 5))\n",
            "  Using cached torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\n",
            "Requirement already satisfied: torch_scatter==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.1.2+pt23cu121)\n",
            "Collecting tqdm==4.66.1 (from -r requirements.txt (line 7))\n",
            "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "Collecting transformers==4.39.1 (from -r requirements.txt (line 8))\n",
            "  Using cached transformers-4.39.1-py3-none-any.whl (8.8 MB)\n",
            "Collecting Unidecode==1.3.8 (from -r requirements.txt (line 9))\n",
            "  Using cached Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro_ppl==1.9.0->-r requirements.txt (line 2)) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from pyro_ppl==1.9.0->-r requirements.txt (line 2)) (2.3.0+cu121)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 5)) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.5.2->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 8)) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 8)) (0.23.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 8)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 8)) (2023.12.25)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.1->-r requirements.txt (line 8))\n",
            "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.1->-r requirements.txt (line 8)) (0.4.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.1->-r requirements.txt (line 8)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2)) (3.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 5)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 5)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 5)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.5.2->-r requirements.txt (line 5)) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.5.2->-r requirements.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.5.2->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.5.2->-r requirements.txt (line 5)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.5.2->-r requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.5.2->-r requirements.txt (line 5)) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->pyro_ppl==1.9.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Installing collected packages: pyro-api, Unidecode, tqdm, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, scipy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, scikit_learn, nvidia-cusolver-cu12, transformers, torch_geometric, pyro_ppl\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.0\n",
            "    Uninstalling transformers-4.41.0:\n",
            "      Successfully uninstalled transformers-4.41.0\n",
            "  Attempting uninstall: torch_geometric\n",
            "    Found existing installation: torch-geometric 2.6.0\n",
            "    Uninstalling torch-geometric-2.6.0:\n",
            "      Successfully uninstalled torch-geometric-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.6.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.2.0 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Unidecode-1.3.8 numpy-1.24.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pyro-api-0.1.2 pyro_ppl-1.9.0 scikit_learn-1.2.0 scipy-1.12.0 tokenizers-0.15.2 torch_geometric-2.5.2 tqdm-4.66.1 transformers-4.39.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tqdm"
                ]
              },
              "id": "4ae8d31edf3e4b8f8117304463d4c3ae"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After Restarting Session"
      ],
      "metadata": {
        "id": "irLPSPIEqewV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "metadata": {
        "id": "-KCAe6BmqHEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee71324-23ae-42d9-aa22-6f36f6cf6c45"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at ./gdrive; to attempt to forcibly remount, call drive.mount(\"./gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCCAD')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "6bXsbHZkqbG6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b116582-e99e-4288-bf8f-1fbf31a525fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/GCCAD'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "WLMJRmzIqbE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d87842-8ef0-48b5-92c5-eed781eed85e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python encoding.py --path ../dataset/pid_to_info_all.json --save_path ../dataset/roberta_embeddings.pkl"
      ],
      "metadata": {
        "id": "OLmkzUX3qr6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43944b55-44bf-495c-c98d-274e750ef73f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 135kB/s]\n",
            "config.json: 100% 481/481 [00:00<00:00, 3.45MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 2.74MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 1.85MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 3.29MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "model.safetensors: 100% 499M/499M [00:16<00:00, 29.6MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "64it [12:41, 11.90s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python build_graph.py --author_dir ../dataset/train_author.json --pub_dir ../dataset/pid_to_info_all.json --save_dir ../dataset/train.pkl --embeddings_dir ../dataset/roberta_embeddings.pkl"
      ],
      "metadata": {
        "id": "T3-206-5qr4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ccda256-daea-43c1-bc52-1952dcd1f68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "done clean pubs\n",
            "done loading embeddings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python build_graph.py"
      ],
      "metadata": {
        "id": "jT_aBNEiqr2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py  --train_dir ../dataset/train.pkl  --test_dir ../dataset/valid.pkl"
      ],
      "metadata": {
        "id": "ufeYhCGzqrXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/gdrive/MyDrive/whoiswho-top-solutions/incorrect_assignment_detection/dataset/pid_to_info_all.json"
      ],
      "metadata": {
        "id": "ANo8flCJ2adJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}